{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel files into DataFrames\n",
    "institution_address_business_it = pd.read_excel('institution_address_Business_IT.xlsx')\n",
    "institution_address_computer_science = pd.read_excel('institution_address_Computer_Science.xlsx')\n",
    "institution_address_digital_design = pd.read_excel('institution_address_Digital_Design.xlsx')\n",
    "institutions_years_papers_business_it = pd.read_excel('institutions_years_papers_Business_IT.xlsx')\n",
    "institutions_years_papers_computer_science = pd.read_excel('institutions_years_papers_Computer_Science.xlsx')\n",
    "institutions_years_papers_digital_design = pd.read_excel('institutions_years_papers_Digital_Design.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of institutions to remove\n",
    "institutions_to_remove = [\n",
    "    'Technologies in Practice (TiP)',\n",
    "    'Digital Design',\n",
    "    'Center for Digital Welfare (CDW)',\n",
    "    'Information Systems and Digital Innovation (ISDI)',\n",
    "    'Computer Science',\n",
    "    'European Blockchain Center (EBC)',\n",
    "    'Center for Climate IT',\n",
    "    'Design Research Section',\n",
    "    'Play, Culture and AI Section',\n",
    "    'Air Lab',\n",
    "    'REFLACT',\n",
    "    'Interaction Design Research Group',\n",
    "    'cisat.dk',\n",
    "    'Media, Art & Design (MAD)',\n",
    "    'IxD Lab',\n",
    "    'Digital Societies and Participation Section',\n",
    "    'NEtwoRks, Data, and Society (NERDS)',\n",
    "    'Welfare Technology - Policy - People - Practices',\n",
    "    'Data-intensive Systems and Applications',\n",
    "    'Research Centre for Government IT',\n",
    "    'ETHOS Lab',\n",
    "    'Robotics, Evolution, and Art Lab (REAL)',\n",
    "    'Co-Design',\n",
    "    'Software Engineering',\n",
    "    'The Maritime Hub (MHub)',\n",
    "    'Center for Digital Play',\n",
    "    'Games Research Group',\n",
    "    'Human Data Interaction Lab (HDI)',\n",
    "    'Software Quality',\n",
    "    'Audio-Visual Computing',\n",
    "    'Programming Logic and Semantics',\n",
    "    'Machine Learning',\n",
    "    'Human-Centered Data Science (HCDS)',\n",
    "    'Danish Institute for IT Program Management (DIIP)',\n",
    "    'Management',\n",
    "    'BUILD Lab',\n",
    "    'Algorithms'\n",
    "]\n",
    "\n",
    "# Remove rows where 'Institution' is in the institutions_to_remove list\n",
    "institutions_years_papers_business_it = institutions_years_papers_business_it[\n",
    "    ~institutions_years_papers_business_it['Institution'].isin(institutions_to_remove)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of institutions to remove\n",
    "institutions_to_remove = [\n",
    "    'Technologies in Practice (TiP)',\n",
    "    'NLPnorth',\n",
    "    'Business IT',\n",
    "    'Digital Design',\n",
    "    'Center for Digital Welfare (CDW)',\n",
    "    'Information Systems and Digital Innovation (ISDI)',\n",
    "    'Computer Science',\n",
    "    'European Blockchain Center (EBC)',\n",
    "    'Center for Climate IT',\n",
    "    'Design Research Section',\n",
    "    'Play, Culture and AI Section',\n",
    "    'Air Lab',\n",
    "    'Creative AI Lab',\n",
    "    'REFLACT',\n",
    "    'Interaction Design Research Group',\n",
    "    'cisat.dk',\n",
    "    'Media, Art & Design (MAD)',\n",
    "    'IxD Lab',\n",
    "    'Digital Societies and Participation Section',\n",
    "    'NEtwoRks, Data, and Society (NERDS)',\n",
    "    'Welfare Technology - Policy - People - Practices',\n",
    "    'Data-intensive Systems and Applications',\n",
    "    'Research Centre for Government IT',\n",
    "    'ETHOS Lab',\n",
    "    'Robotics, Evolution, and Art Lab (REAL)',\n",
    "    'Co-Design',\n",
    "    'Center for Computing Education Research (CCER)',\n",
    "    'Software Engineering',\n",
    "    'The Maritime Hub (MHub)',\n",
    "    'Center for Digital Play',\n",
    "    'Games Research Group',\n",
    "    'Human Data Interaction Lab (HDI)',\n",
    "    'Software Quality',\n",
    "    'Audio-Visual Computing',\n",
    "    'Programming Logic and Semantics',\n",
    "    'Machine Learning',\n",
    "    'Human-Centered Data Science (HCDS)',\n",
    "    'Danish Institute for IT Program Management (DIIP)',\n",
    "    'Management',\n",
    "    'BUILD Lab',\n",
    "    'Procedural eXpression Lab (PXL)',\n",
    "    'Algorithms'\n",
    "]\n",
    "\n",
    "# Remove rows where 'Institution' is in the institutions_to_remove list\n",
    "institutions_years_papers_computer_science = institutions_years_papers_computer_science[\n",
    "    ~institutions_years_papers_computer_science['Institution'].isin(institutions_to_remove)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of institutions to remove\n",
    "institutions_to_remove = [\n",
    "    'Technologies in Practice (TiP)',\n",
    "    'NLPnorth',\n",
    "    'Business IT',\n",
    "    'Digital Design',\n",
    "    'Center for Digital Welfare (CDW)',\n",
    "    'Information Systems and Digital Innovation (ISDI)',\n",
    "    'Computer Science',\n",
    "    'European Blockchain Center (EBC)',\n",
    "    'Center for Climate IT',\n",
    "    'Design Research Section',\n",
    "    'Play, Culture and AI Section',\n",
    "    'Air Lab',\n",
    "    'Creative AI Lab',\n",
    "    'REFLACT',\n",
    "    'Interaction Design Research Group',\n",
    "    'cisat.dk',\n",
    "    'Media, Art & Design (MAD)',\n",
    "    'IxD Lab',\n",
    "    'Digital Societies and Participation Section',\n",
    "    'NEtwoRks, Data, and Society (NERDS)',\n",
    "    'Welfare Technology - Policy - People - Practices',\n",
    "    'Data-intensive Systems and Applications',\n",
    "    'Research Centre for Government IT',\n",
    "    'ETHOS Lab',\n",
    "    'Robotics, Evolution, and Art Lab (REAL)',\n",
    "    'Co-Design',\n",
    "    'Center for Computing Education Research (CCER)',\n",
    "    'Software Engineering',\n",
    "    'The Maritime Hub (MHub)',\n",
    "    'Center for Digital Play',\n",
    "    'Games Research Group',\n",
    "    'Human Data Interaction Lab (HDI)',\n",
    "    'Software Quality',\n",
    "    'Audio-Visual Computing',\n",
    "    'Programming Logic and Semantics',\n",
    "    'Machine Learning',\n",
    "    'Human-Centered Data Science (HCDS)',\n",
    "    'Danish Institute for IT Program Management (DIIP)',\n",
    "    'Management',\n",
    "    'BUILD Lab',\n",
    "    'Procedural eXpression Lab (PXL)',\n",
    "    'Algorithms'\n",
    "]\n",
    "\n",
    "# Remove rows where 'Institution' is in the institutions_to_remove list\n",
    "institutions_years_papers_digital_design = institutions_years_papers_digital_design[\n",
    "    ~institutions_years_papers_digital_design['Institution'].isin(institutions_to_remove)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 'area' column to institutions_years_papers_business_it with value \"Business IT\"\n",
    "institutions_years_papers_business_it['Business IT'] = '1'\n",
    "institutions_years_papers_business_it['Computer Science'] = '0'\n",
    "institutions_years_papers_business_it['Digital Design'] = '0'\n",
    "\n",
    "# Adding 'area' column to institutions_years_papers_computer_science with value \"Computer Science\"\n",
    "institutions_years_papers_computer_science['Computer Science'] = '1'\n",
    "institutions_years_papers_computer_science['Business IT'] = '0'\n",
    "institutions_years_papers_computer_science['Digital Design'] = '0'\n",
    "\n",
    "# Adding 'area' column to institutions_years_papers_digital_design_cleaned with value \"Digital Design\"\n",
    "institutions_years_papers_digital_design['Digital Design'] = '1'\n",
    "institutions_years_papers_digital_design['Computer Science'] = '0'\n",
    "institutions_years_papers_digital_design['Business IT'] = '0'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Institution', 'Year', 'Title', 'Business IT', 'Computer Science',\n",
       "       'Digital Design'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the three DataFrames into one using pd.concat\n",
    "combined_df = pd.concat([\n",
    "    institutions_years_papers_business_it,\n",
    "    institutions_years_papers_computer_science,\n",
    "    institutions_years_papers_digital_design\n",
    "], ignore_index=True)\n",
    "\n",
    "# Verify the result by displaying the first few rows of the combined DataFrame\n",
    "combined_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates after cleaning: 0\n",
      "                                         Institution  Year  \\\n",
      "0                                      3DInteractive  2016   \n",
      "1  4Brain, Department of Neurology, Ghent Univers...  2021   \n",
      "2                            A.P. Møller - Mærsk A/S  2024   \n",
      "3                                    AAL Association  2017   \n",
      "4                                                ABB  2012   \n",
      "\n",
      "                                               Title Business IT  \\\n",
      "0                 How Good Is Multi-Pivot Quicksort?           0   \n",
      "1  Feasibility of transcutaneous auricular vagus ...           1   \n",
      "2  Difficulty Modelling in Mobile Puzzle Games: A...           0   \n",
      "3     Documenting emerging practices incl appendices           0   \n",
      "4    Interaction with the dirty, dangerous, and dull           0   \n",
      "\n",
      "  Computer Science Digital Design  \n",
      "0                1              0  \n",
      "1                0              0  \n",
      "2                0              1  \n",
      "3                0              1  \n",
      "4                0              1  \n"
     ]
    }
   ],
   "source": [
    "# Group by 'Institution', 'Year', 'Title' and take the maximum for 'Business IT', 'Computer Science', 'Digital Design'\n",
    "combined_df_cleaned = combined_df.groupby(['Institution', 'Year', 'Title'], as_index=False).agg({\n",
    "    'Business IT': 'max',\n",
    "    'Computer Science': 'max',\n",
    "    'Digital Design': 'max'\n",
    "})\n",
    "\n",
    "# Verify the result\n",
    "print(f\"Number of duplicates after cleaning: {combined_df_cleaned.duplicated(subset=['Institution', 'Year', 'Title']).sum()}\")\n",
    "print(combined_df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to Institution_Papers.xlsx successfully.\n"
     ]
    }
   ],
   "source": [
    "# Export the cleaned DataFrame to an Excel file\n",
    "combined_df_cleaned.to_excel('Institution_Papers.xlsx', index=False)\n",
    "\n",
    "# Confirmation message\n",
    "print(\"DataFrame exported to Institution_Papers.xlsx successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates after cleaning: 0\n",
      "          Institution  Year  \\\n",
      "0  Aalborg University  2024   \n",
      "1  Aalborg University  2024   \n",
      "2  Aalborg University  2023   \n",
      "3  Aalborg University  2023   \n",
      "4  Aalborg University  2023   \n",
      "\n",
      "                                               Title         area  \n",
      "0  The role of psychological safety in promoting ...  Business IT  \n",
      "1  Approaching digital anthropocene(s): A double ...  Business IT  \n",
      "2  Proposing organisational usability as an enabl...  Business IT  \n",
      "3  Opening the Blind Box: A multimodal account of...  Business IT  \n",
      "4                          Organisations as material  Business IT  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Step 1: Identify duplicate rows based on 'Institution', 'Year', and 'Title' columns\n",
    "duplicates = combined_df.duplicated(subset=['Institution', 'Year', 'Title'], keep=False)\n",
    "\n",
    "# Step 2: Create a mask for duplicates\n",
    "duplicate_rows = combined_df[duplicates]\n",
    "\n",
    "# Step 3: Update the 'area' column of duplicates to 'Multiple areas'\n",
    "combined_df.loc[duplicates, 'area'] = 'Multiple areas'\n",
    "\n",
    "# Step 4: Drop all but one instance of each duplicate row (keeping the first)\n",
    "combined_df_cleaned = combined_df.drop_duplicates(subset=['Institution', 'Year', 'Title'], keep='first')\n",
    "\n",
    "# Step 5: Verify the result by printing the cleaned DataFrame and checking for duplicates\n",
    "print(f\"Number of duplicates after cleaning: {combined_df_cleaned.duplicated(subset=['Institution', 'Year', 'Title']).sum()}\")\n",
    "print(combined_df_cleaned.head())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Business IT' 'Multiple areas' 'Computer Science' 'Digital Design']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Show all the unique values in the 'area' column of the cleaned DataFrame\n",
    "unique_area_values = combined_df_cleaned['area'].unique()\n",
    "\n",
    "# Display the unique values\n",
    "print(unique_area_values)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Institution Name  \\\n",
      "0                 Aalborg University   \n",
      "1                  Aarhus University   \n",
      "2  Johann Wolfgang Goethe University   \n",
      "3                Roskilde University   \n",
      "4           University of Copenhagen   \n",
      "\n",
      "                                             Address  \n",
      "0  Address :   Fredrik Bajers Vej 7K, 9220 Aalbor...  \n",
      "1  Address :   Nordre Ringgade 1, 8000 Aarhus Cen...  \n",
      "2  Address :   Theodor-W.-Adorno-Platz 1, 60629 F...  \n",
      "3       Address :   Universitetsvej 1, 4000 Roskilde  \n",
      "4           Address :   Nørregade 10, 1172 København  \n"
     ]
    }
   ],
   "source": [
    "# Combine the three institution address DataFrames into one\n",
    "combined_address_df = pd.concat([\n",
    "    institution_address_business_it,\n",
    "    institution_address_computer_science,\n",
    "    institution_address_digital_design\n",
    "], ignore_index=True)\n",
    "\n",
    "# Verify the result by displaying the first few rows of the combined DataFrame\n",
    "print(combined_address_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows based on 'Institution Name': 737\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates based on the 'Institution Name' column\n",
    "duplicate_institutions = combined_address_df.duplicated(subset=['Institution Name'], keep=False)\n",
    "\n",
    "# Count the number of duplicate rows\n",
    "num_duplicate_institutions = duplicate_institutions.sum()\n",
    "\n",
    "# Display the number of duplicates\n",
    "print(f\"Number of duplicate rows based on 'Institution Name': {num_duplicate_institutions}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing duplicates: 958\n",
      "                    Institution Name  \\\n",
      "0                 Aalborg University   \n",
      "1                  Aarhus University   \n",
      "2  Johann Wolfgang Goethe University   \n",
      "3                Roskilde University   \n",
      "4           University of Copenhagen   \n",
      "\n",
      "                                             Address  \n",
      "0  Address :   Fredrik Bajers Vej 7K, 9220 Aalbor...  \n",
      "1  Address :   Nordre Ringgade 1, 8000 Aarhus Cen...  \n",
      "2  Address :   Theodor-W.-Adorno-Platz 1, 60629 F...  \n",
      "3       Address :   Universitetsvej 1, 4000 Roskilde  \n",
      "4           Address :   Nørregade 10, 1172 København  \n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates based on the 'Institution Name' column, keeping the first occurrence\n",
    "combined_address_df_cleaned = combined_address_df.drop_duplicates(subset=['Institution Name'], keep='first')\n",
    "\n",
    "# Verify the result by checking the number of remaining rows and displaying the first few rows\n",
    "print(f\"Number of rows after removing duplicates: {len(combined_address_df_cleaned)}\")\n",
    "print(combined_address_df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Institution Name  \\\n",
      "0                 Aalborg University   \n",
      "1                  Aarhus University   \n",
      "2  Johann Wolfgang Goethe University   \n",
      "3                Roskilde University   \n",
      "4           University of Copenhagen   \n",
      "\n",
      "                                             Address  \n",
      "0            Fredrik Bajers Vej 7K, 9220 Aalborg Øst  \n",
      "1             Nordre Ringgade 1, 8000 Aarhus Centrum  \n",
      "2  Theodor-W.-Adorno-Platz 1, 60629 Frankfurt am ...  \n",
      "3                   Universitetsvej 1, 4000 Roskilde  \n",
      "4                       Nørregade 10, 1172 København  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikas\\AppData\\Local\\Temp\\ipykernel_8116\\3503200363.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_address_df_cleaned['Address'] = combined_address_df_cleaned['Address'].str.replace(r\"^(Address :|Headquarters :)\\s*\", \"\", regex=True)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Filter out rows where 'Address' contains \"No address found\"\n",
    "#filtered_combined_address_df = combined_address_df_cleaned[~combined_address_df_cleaned['Address'].str.contains(\"No address found\", na=False)]\n",
    "\n",
    "# Step 2: Remove the \"Address :\" and \"Headquarters :\" prefixes from the 'Address' column\n",
    "combined_address_df_cleaned['Address'] = combined_address_df_cleaned['Address'].str.replace(r\"^(Address :|Headquarters :)\\s*\", \"\", regex=True)\n",
    "\n",
    "# Verify the result by displaying the first few rows of the cleaned DataFrame\n",
    "print(combined_address_df_cleaned[['Institution Name', 'Address']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to Institution_Address.xlsx successfully.\n"
     ]
    }
   ],
   "source": [
    "# Export the cleaned DataFrame to an Excel file\n",
    "combined_address_df_cleaned.to_excel('Institution_Address.xlsx', index=False)\n",
    "\n",
    "# Confirmation message\n",
    "print(\"DataFrame exported to Institution_Address.xlsx successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Institution  Year  \\\n",
      "0  Aalborg University  2024   \n",
      "1  Aalborg University  2024   \n",
      "2  Aalborg University  2023   \n",
      "3  Aalborg University  2023   \n",
      "4  Aalborg University  2023   \n",
      "\n",
      "                                               Title         area  \\\n",
      "0  The role of psychological safety in promoting ...  Business IT   \n",
      "1  Approaching digital anthropocene(s): A double ...  Business IT   \n",
      "2  Proposing organisational usability as an enabl...  Business IT   \n",
      "3  Opening the Blind Box: A multimodal account of...  Business IT   \n",
      "4                          Organisations as material  Business IT   \n",
      "\n",
      "                                   Address  \n",
      "0  Fredrik Bajers Vej 7K, 9220 Aalborg Øst  \n",
      "1  Fredrik Bajers Vej 7K, 9220 Aalborg Øst  \n",
      "2  Fredrik Bajers Vej 7K, 9220 Aalborg Øst  \n",
      "3  Fredrik Bajers Vej 7K, 9220 Aalborg Øst  \n",
      "4  Fredrik Bajers Vej 7K, 9220 Aalborg Øst  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Rename 'Institution Name' in filtered_combined_address_df to 'Institution' for the merge\n",
    "filtered_combined_address_df = combined_address_df_cleaned.rename(columns={'Institution Name': 'Institution'})\n",
    "\n",
    "# Step 2: Merge the two DataFrames on the 'Institution' column\n",
    "df = pd.merge(combined_df_cleaned, filtered_combined_address_df[['Institution', 'Address']], on='Institution', how='left')\n",
    "\n",
    "# Step 3: Verify the result by displaying the first few rows of the merged DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install folium geopy ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m geolocator \u001b[38;5;241m=\u001b[39m Nominatim(user_agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstitution_locator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# We now use the entire df dataset (no filtering to 100 cases)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m df_full \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m  \u001b[38;5;66;03m# Assuming df contains your full dataset\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Step 1: Create a scrollable bar for year selection\u001b[39;00m\n\u001b[0;32m     14\u001b[0m years \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(df_full[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import folium\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Geolocator setup\n",
    "geolocator = Nominatim(user_agent=\"institution_locator\")\n",
    "\n",
    "# We now use the entire df dataset (no filtering to 100 cases)\n",
    "df_full = df  # Assuming df contains your full dataset\n",
    "\n",
    "# Step 1: Create a scrollable bar for year selection\n",
    "years = sorted(df_full['Year'].unique())\n",
    "year_slider = widgets.SelectionSlider(\n",
    "    options=years,\n",
    "    value=years[0],\n",
    "    description='Year:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True\n",
    ")\n",
    "\n",
    "# Step 2: Create a set of checkboxes for area filtering\n",
    "areas = df_full['area'].unique()\n",
    "area_checkboxes = widgets.SelectMultiple(\n",
    "    options=areas,\n",
    "    value=tuple(areas),  # Convert to tuple\n",
    "    description='Areas:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Step 3: Function to update the map based on selected year and area\n",
    "def update_map(year, selected_areas):\n",
    "    # Filter the dataframe by year and areas\n",
    "    filtered_df = df_full[(df_full['Year'] == year) & (df_full['area'].isin(selected_areas))]\n",
    "    \n",
    "    # Create a map centered on a default location\n",
    "    map_center = [55.6761, 12.5683]  # Center the map on Copenhagen for example\n",
    "    institution_map = folium.Map(location=map_center, zoom_start=5)\n",
    "\n",
    "    # Group data by institution to ensure one pin per institution\n",
    "    grouped_df = filtered_df.groupby('Institution')\n",
    "    \n",
    "    for institution, group in grouped_df:\n",
    "        # Geocode institution address (Cleaned Address)\n",
    "        address = group['Address'].values[0]\n",
    "        try:\n",
    "            location = geolocator.geocode(address)\n",
    "            if location:\n",
    "                # Generate the content for the popup (group articles by area and show count)\n",
    "                popup_content = f\"<b>{institution}</b><br>\"\n",
    "                for area in selected_areas:\n",
    "                    # Count the number of articles in the chosen year and area\n",
    "                    article_count = group[group['area'] == area]['Title'].count()\n",
    "                    if article_count > 0:\n",
    "                        popup_content += f\"<b>{area}:</b> {article_count} articles<br>\"\n",
    "                \n",
    "                # Add the marker to the map\n",
    "                folium.Marker(\n",
    "                    [location.latitude, location.longitude],\n",
    "                    popup=popup_content\n",
    "                ).add_to(institution_map)\n",
    "            # Sleep to respect the geocoding service rate limit\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error geocoding address: {address} - {e}\")\n",
    "    \n",
    "    return institution_map\n",
    "\n",
    "# Step 4: Function to handle widget interaction\n",
    "def update_display(year, selected_areas):\n",
    "    # Clear the previous display\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Update the map based on selected year and areas\n",
    "    updated_map = update_map(year, selected_areas)\n",
    "    \n",
    "    # Display the updated map and widgets\n",
    "    display(updated_map, year_slider, area_checkboxes)\n",
    "\n",
    "# Step 5: Set up interaction and display widgets\n",
    "interactive_map = widgets.interactive_output(update_display, {'year': year_slider, 'selected_areas': area_checkboxes})\n",
    "\n",
    "# Display the widgets and the interactive map\n",
    "display(year_slider, area_checkboxes, interactive_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: folium in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (0.17.0)\n",
      "Collecting flask\n",
      "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: geopy in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: branca>=0.6.0 in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (from folium) (0.8.0)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (from folium) (3.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (from folium) (2.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (from folium) (2.32.3)\n",
      "Requirement already satisfied: xyzservices in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (from folium) (2024.9.0)\n",
      "Collecting Werkzeug>=3.0.0 (from flask)\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting itsdangerous>=2.1.2 (from flask)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting click>=8.1.3 (from flask)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting blinker>=1.6.2 (from flask)\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (from geopy) (2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (from jinja2>=2.9->folium) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (from requests->folium) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (from requests->folium) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (from requests->folium) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mikas\\desktop\\.conda\\lib\\site-packages (from requests->folium) (2024.8.30)\n",
      "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "Downloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Installing collected packages: Werkzeug, itsdangerous, click, blinker, flask\n",
      "Successfully installed Werkzeug-3.0.4 blinker-1.8.2 click-8.1.7 flask-3.0.3 itsdangerous-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script flask.exe is installed in 'c:\\Users\\Mikas\\Desktop\\.conda\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "#pip install folium flask geopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5001\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error geocoding address: Atlanta, GA 30302, United States - HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Atlanta%2C+GA+30302%2C+United+States&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "Error geocoding address: 201 Old Main, University Park, PA 16802, United States - HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=201+Old+Main%2C+University+Park%2C+PA+16802%2C+United+States&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n",
      "Error geocoding address: Adelaide SA 5005, Australia - HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Max retries exceeded with url: /search?q=Adelaide+SA+5005%2C+Australia&format=json&limit=1 (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out. (read timeout=1)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Oct/2024 14:45:34] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Oct/2024 14:48:43] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Oct/2024 14:48:46] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "from flask import Flask, render_template, request\n",
    "from geopy.geocoders import Nominatim\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Assuming df_full is your dataset\n",
    "df_full = df\n",
    "\n",
    "# Geolocator setup\n",
    "geolocator = Nominatim(user_agent=\"institution_locator\")\n",
    "\n",
    "# Create a Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Home route to display the map and filter controls\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def home():\n",
    "    year = 2020  # Default year\n",
    "    selected_areas = df_full['area'].unique()  # Default areas (all)\n",
    "\n",
    "    # If the form is submitted, get the selected values\n",
    "    if request.method == 'POST':\n",
    "        try:\n",
    "            year = int(request.form.get('year'))\n",
    "            selected_areas = request.form.getlist('areas')\n",
    "        except Exception as e:\n",
    "            print(f\"Error in form data: {e}\")\n",
    "\n",
    "    # Filter the dataframe based on the selected year and areas\n",
    "    filtered_df = df_full[(df_full['Year'] == year) & (df_full['area'].isin(selected_areas))]\n",
    "\n",
    "    # Create a map centered on a default location\n",
    "    map_center = [55.6761, 12.5683]  # Example: Copenhagen\n",
    "    institution_map = folium.Map(location=map_center, zoom_start=5)\n",
    "\n",
    "    # Group data by institution to ensure one pin per institution\n",
    "    grouped_df = filtered_df.groupby('Institution')\n",
    "\n",
    "    for institution, group in grouped_df:\n",
    "        # Geocode institution address (Cleaned Address)\n",
    "        address = group['Address'].values[0]\n",
    "        try:\n",
    "            location = geolocator.geocode(address)\n",
    "            if location:\n",
    "                # Generate the content for the popup (group articles by area and show count)\n",
    "                popup_content = f\"<b>{institution}</b><br>\"\n",
    "                for area in selected_areas:\n",
    "                    # Count the number of articles in the chosen year and area\n",
    "                    article_count = group[group['area'] == area]['Title'].count()\n",
    "                    if article_count > 0:\n",
    "                        popup_content += f\"<b>{area}:</b> {article_count} articles<br>\"\n",
    "\n",
    "                # Add the marker to the map\n",
    "                folium.Marker(\n",
    "                    [location.latitude, location.longitude],\n",
    "                    popup=popup_content\n",
    "                ).add_to(institution_map)\n",
    "            # Sleep to respect the geocoding service rate limit\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error geocoding address: {address} - {e}\")\n",
    "\n",
    "    # Save map as HTML\n",
    "    map_html = institution_map._repr_html_()\n",
    "\n",
    "    # Render the template with the map and filters\n",
    "    return render_template('index.html', map_html=map_html, year=year, areas=df_full['area'].unique(), selected_areas=selected_areas)\n",
    "\n",
    "# Start the Flask app\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        app.run(debug=True, port=5001, use_reloader=False)  # Disable the reloader to prevent SystemExit\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting the Flask app: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
